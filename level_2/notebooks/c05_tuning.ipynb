{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..', '..'))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "    \n",
    "import mlflow\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models import MetricThreshold\n",
    "from hyperopt import fmin, hp, STATUS_OK, tpe\n",
    "\n",
    "from level_2.src.utils import utils\n",
    "from level_2.src.data.data_load import DataLoad\n",
    "from level_2.src.data.data_validation import DataValidation\n",
    "from level_2.src.data.data_transform import DataTransform\n",
    "from level_2.src.data.data_preprocess import DataPreprocess\n",
    "from level_2.src.train.model_training import ModelTraining\n",
    "from level_2.src.evaluation.classifier_eval import ClassifierEvaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:09\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mReading data from CSV file...\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData read successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_data_file = os.path.join(ROOT_DIR, 'level_2', 'data', 'raw', 'train.csv')\n",
    "\n",
    "data_load = DataLoad()\n",
    "df = data_load.run(train_data_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation started\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation passed\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation successeful\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_validation = DataValidation()\n",
    "\n",
    "is_valid = data_validation.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = DataTransform(df)\n",
    "\n",
    "x_train, x_test, y_train, y_test = data_transform.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1701960364665, experiment_id='1', last_update_time=1701960364665, lifecycle_stage='active', name='prob_loan', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"prob_loan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:10\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:11\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.7076126693231048\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='baseline'):\n",
    "    mlflow.set_tag('model_name', 'baseline')\n",
    "    \n",
    "    # 1. preprocessing\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('imputer', MeanMedianImputer(variables=utils.load_config().get('imputer_variables'))),\n",
    "            ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocessor = DataPreprocess(pipe)    \n",
    "    preprocessor.train(x_train)\n",
    "    \n",
    "    x_train_processed = preprocessor.transform(x_train)    \n",
    "    x_test_processed = preprocessor.transform(x_test)\n",
    "    \n",
    "    joblib.dump(preprocessor, os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "    \n",
    "    # 1.1. artifact logging - preprocessor\n",
    "    mlflow.log_artifact(os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "    \n",
    "    # 1.2. artifact params - config\n",
    "    log_params = {\n",
    "        'imputer': pipe['imputer'],\n",
    "        'scaler': pipe['scaler']\n",
    "    }\n",
    "    mlflow.log_params(params=log_params)\n",
    "    \n",
    "    # 2. begin with cross validation\n",
    "    model = LogisticRegression(random_state=utils.load_config().get('random_state'))\n",
    "    model_eval = ClassifierEvaluation(model, x_train_processed, y_train, k_fold=5)\n",
    "    roc_auc_scores = model_eval.cross_val_eval()\n",
    "    \n",
    "    \n",
    "    # 2.1 log metrics\n",
    "    mlflow.log_metric('roc_auc_scores', roc_auc_scores.mean())\n",
    "    \n",
    "    # 3. train model\n",
    "    model.fit(x_train_processed, y_train)\n",
    "    \n",
    "    # 4. evaluate model under test data\n",
    "    y_pred = model_eval.model.predict_proba(x_test_processed)[:, 1]\n",
    "    val_roc_auc_score = model_eval.evaluate_predictions(y_test, y_pred)\n",
    "    \n",
    "    # 4.1 log metrics\n",
    "    mlflow.log_metric('val_roc_auc_score', val_roc_auc_score)\n",
    "    \n",
    "    # 5. log model\n",
    "    mlflow.sklearn.log_model(model, 'lr_model', pyfunc_predict_fn='predict_proba')\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Discretiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run(run_name='hyperopt'):\n",
    "        mlflow.set_tag('model_name', 'lr_hyperopt')\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # 1. preprocessing\n",
    "        pipe = Pipeline(\n",
    "            [\n",
    "                ('imputer', MeanMedianImputer(variables=utils.load_config().get('imputer_variables'))),\n",
    "                ('discretiser', EqualFrequencyDiscretiser(variables=utils.load_config().get('discretiser_variables'))),\n",
    "                ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        preprocessor = DataPreprocess(pipe)    \n",
    "        preprocessor.train(x_train)\n",
    "        \n",
    "        x_train_processed = preprocessor.transform(x_train)    \n",
    "        x_test_processed = preprocessor.transform(x_test)\n",
    "        \n",
    "        joblib.dump(preprocessor, os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "        \n",
    "        # 1.1. artifact logging - preprocessor\n",
    "        mlflow.log_artifact(os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "        \n",
    "        # 1.2. artifact params - config\n",
    "        log_params = {\n",
    "            'imputer': pipe['imputer'],\n",
    "            'discretiser': pipe['discretiser'],\n",
    "            'scaler': pipe['scaler']\n",
    "        }\n",
    "        mlflow.log_params(params=log_params)\n",
    "        \n",
    "        # 2. begin with cross validation\n",
    "        model = LogisticRegression(**params)\n",
    "        model_eval = ClassifierEvaluation(model, x_train_processed, y_train, k_fold=5)\n",
    "        roc_auc_scores = model_eval.cross_val_eval()\n",
    "        \n",
    "        \n",
    "        # 2.1 log metrics\n",
    "        mlflow.log_metric('roc_auc_scores', roc_auc_scores.mean())\n",
    "        \n",
    "        # 3. train model\n",
    "        model.fit(x_train_processed, y_train)\n",
    "        \n",
    "        # 4. evaluate model under test data\n",
    "        y_pred = model_eval.model.predict_proba(x_test_processed)[:, 1]\n",
    "        val_roc_auc_score = model_eval.evaluate_predictions(y_test, y_pred)\n",
    "        \n",
    "        # 4.1 log metrics\n",
    "        mlflow.log_metric('val_roc_auc_score', val_roc_auc_score)\n",
    "        \n",
    "        # 5. log model\n",
    "        candidate_model_uri = mlflow.sklearn.log_model(model, 'lr_hyperopt').model_uri\n",
    "        \n",
    "        # 6. infer signature\n",
    "        signature = infer_signature(x_test_processed, y_test)\n",
    "        eval_data = x_test_processed\n",
    "        eval_data['label'] = y_test\n",
    "        \n",
    "        threshold = {\n",
    "            'accuracy_score': MetricThreshold(\n",
    "                threshold=0.1,\n",
    "                min_absolute_change=0.05,\n",
    "                min_relative_change=0.05,\n",
    "                greater_is_better=True\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        baseline_model = DummyClassifier(\n",
    "                            strategy='uniform',\n",
    "                            random_state=utils.load_config().get('random_state')\n",
    "                        ).fit(x_train_processed, y_train)\n",
    "        baseline_model_uri = mlflow.sklearn.log_model(baseline_model, 'baseline_model', signature=signature).model_uri\n",
    "        \n",
    "        # 7. log model with threshold\n",
    "        mlflow.evaluate(\n",
    "            candidate_model_uri,\n",
    "            eval_data,\n",
    "            targets='label',\n",
    "            model_type='classifier',\n",
    "            validation_thresholds=threshold,\n",
    "            baseline_model=baseline_model_uri\n",
    "        )\n",
    "        \n",
    "        mlflow.end_run()\n",
    "        \n",
    "        return {'loss': -roc_auc_scores.mean(), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'warm_start': hp.choice('warm_start', [True, False]),\n",
    "    'fit_intercept': hp.choice('fit_intercept', [True, False]),\n",
    "    'tol': hp.uniform('tol', 0.00001, 0.0001),\n",
    "    'C': hp.uniform('C', 0.05, 3),\n",
    "    'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "    'max_iter': hp.choice('max_iter', range(100, 1000)),\n",
    "    'multi_class': 'auto',\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:14\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:17\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:18\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.7987182283105457\u001b[0m\n",
      "  0%|          | 0/5 [00:03<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 25.27it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 41.89it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 57.84it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 71.40it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 84.90it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 82.33it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 30.83it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 55.31it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 69.99it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 88.77it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 104.28it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 101.32it/s]\n",
      "2023/12/11 10:35:23 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/11 10:35:23 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/11 10:35:23 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:35:23 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:35:23 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:35:25 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "2023/12/11 10:35:25 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/11 10:35:28 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/11 10:35:28 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:35:28 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:35:28 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:35:28 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/11 10:35:28 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:35:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:35:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:28\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:31\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.7986326519894509\u001b[0m\n",
      " 20%|██        | 1/5 [00:17<00:54, 13.70s/trial, best loss: -0.7922994429115655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 46.88it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 57.14it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 76.27it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 94.65it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 110.99it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 104.23it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 37.56it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 58.05it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 81.36it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 97.79it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 113.18it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 108.01it/s]\n",
      "2023/12/11 10:35:36 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/11 10:35:36 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/11 10:35:36 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:35:36 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:35:37 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:35:38 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "2023/12/11 10:35:39 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/11 10:35:41 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/11 10:35:41 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:35:41 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:35:41 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:35:41 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/11 10:35:41 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:35:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:41\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:35:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.7985288678012609\u001b[0m\n",
      " 40%|████      | 2/5 [00:28<00:40, 13.50s/trial, best loss: -0.7922994429115655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 33.42it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 53.99it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 75.95it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 93.90it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 111.63it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 107.73it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 194.26it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 137.08it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 164.93it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 175.20it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 197.45it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 186.15it/s]\n",
      "2023/12/11 10:35:48 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/11 10:35:48 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/11 10:35:48 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:35:48 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:35:48 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:35:50 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "2023/12/11 10:35:50 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/11 10:35:52 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/11 10:35:52 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:35:52 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:35:52 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:35:52 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/11 10:35:52 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:35:52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:52\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:35:53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:35:53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:35:54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.838976892162301\u001b[0m\n",
      " 60%|██████    | 3/5 [00:39<00:24, 12.40s/trial, best loss: -0.7922994429115655]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 37.92it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 59.07it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 78.27it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 98.24it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 116.22it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 110.19it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 40.07it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 70.67it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 95.79it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 118.11it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 138.01it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 132.68it/s]\n",
      "2023/12/11 10:35:58 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/11 10:35:58 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/11 10:35:59 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:35:59 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:35:59 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:36:01 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "2023/12/11 10:36:01 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/11 10:36:03 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/11 10:36:03 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:36:03 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:36:03 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:36:03 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/11 10:36:03 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-11 10:36:03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-11 10:36:03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:36:03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:36:03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m  \n",
      "\u001b[2m2023-12-11 10:36:03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-11 10:36:03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:36:13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:36:16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-11 10:36:16\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.8513431481653442\u001b[0m\n",
      " 80%|████████  | 4/5 [01:01<00:11, 11.76s/trial, best loss: -0.8349269358560152]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 65.81it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 79.60it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 61.74it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 78.21it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 93.75it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 91.37it/s]\n",
      "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading artifacts:  20%|##        | 1/5 [00:00<00:00, 30.66it/s]\n",
      "Downloading artifacts:  40%|####      | 2/5 [00:00<00:00, 50.15it/s]\n",
      "Downloading artifacts:  60%|######    | 3/5 [00:00<00:00, 66.47it/s]\n",
      "Downloading artifacts:  80%|########  | 4/5 [00:00<00:00, 78.85it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 89.67it/s]\n",
      "Downloading artifacts: 100%|##########| 5/5 [00:00<00:00, 82.44it/s]\n",
      "2023/12/11 10:36:21 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "\n",
      "2023/12/11 10:36:21 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "\n",
      "2023/12/11 10:36:21 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:36:21 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:36:21 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:36:23 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "\n",
      "2023/12/11 10:36:23 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "\n",
      "2023/12/11 10:36:25 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "\n",
      "2023/12/11 10:36:25 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "\n",
      "2023/12/11 10:36:25 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "\n",
      "2023/12/11 10:36:25 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "\n",
      "2023/12/11 10:36:25 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "\n",
      "2023/12/11 10:36:25 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:11<00:00, 14.23s/trial, best loss: -0.8473732319757177]\n"
     ]
    }
   ],
   "source": [
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment = dict(mlflow.get_experiment_by_name('prob_loan'))\n",
    "experiment_id = current_experiment['experiment_id']\n",
    "\n",
    "df_mlflow = mlflow.search_runs(\n",
    "    experiment_ids=experiment_id,\n",
    "    filter_string='metrics.val_roc_auc_score < 1'\n",
    ").sort_values(by='metrics.val_roc_auc_score', ascending=False)\n",
    "\n",
    "best_run_id = df_mlflow.iloc[0]['run_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params.imputer</th>\n",
       "      <th>params.discretiser</th>\n",
       "      <th>params.scaler</th>\n",
       "      <th>params.class_weight</th>\n",
       "      <th>params.warm_start</th>\n",
       "      <th>params.solver</th>\n",
       "      <th>params.max_iter</th>\n",
       "      <th>params.fit_intercept</th>\n",
       "      <th>params.tol</th>\n",
       "      <th>params.C</th>\n",
       "      <th>params.multi_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MeanMedianImputer(variables=['RendaMensal', 'N...</td>\n",
       "      <td>EqualFrequencyDiscretiser(variables=['TaxaDeUt...</td>\n",
       "      <td>SklearnTransformerWrapper(transformer=Standard...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>saga</td>\n",
       "      <td>852</td>\n",
       "      <td>False</td>\n",
       "      <td>4.157161747165617e-05</td>\n",
       "      <td>0.6849956166046255</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      params.imputer  \\\n",
       "0  MeanMedianImputer(variables=['RendaMensal', 'N...   \n",
       "\n",
       "                                  params.discretiser  \\\n",
       "0  EqualFrequencyDiscretiser(variables=['TaxaDeUt...   \n",
       "\n",
       "                                       params.scaler params.class_weight  \\\n",
       "0  SklearnTransformerWrapper(transformer=Standard...                None   \n",
       "\n",
       "  params.warm_start params.solver params.max_iter params.fit_intercept  \\\n",
       "0             False          saga             852                False   \n",
       "\n",
       "              params.tol            params.C params.multi_class  \n",
       "0  4.157161747165617e-05  0.6849956166046255               auto  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlflow.loc[df_mlflow['run_id'] == best_run_id, col_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8513431481653442\n"
     ]
    }
   ],
   "source": [
    "df_mlflow = mlflow.search_runs(\n",
    "    filter_string='metrics.val_roc_auc_score < 1'\n",
    ").sort_values(by='metrics.val_roc_auc_score', ascending=False)\n",
    "\n",
    "best_run_id = df_mlflow.iloc[0]['run_id']\n",
    "\n",
    "col_params = [\n",
    "    'params.imputer',\n",
    "    'params.discretiser',\n",
    "    'params.scaler',\n",
    "    'params.class_weight',\n",
    "    'params.warm_start',\n",
    "    'params.solver',\n",
    "    'params.max_iter',\n",
    "    'params.fit_intercept',\n",
    "    'params.tol',\n",
    "    'params.C',\n",
    "    'params.multi_class'            \n",
    "]\n",
    "\n",
    "df_best_params = df_mlflow.loc[df_mlflow['run_id'] == best_run_id, :]\n",
    "\n",
    "best_roc_auc_score = df_mlflow.iloc[0]['metrics.val_roc_auc_score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
