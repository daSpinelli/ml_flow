{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname('__file__'), '..', '..'))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "    \n",
    "import mlflow\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.models import MetricThreshold\n",
    "\n",
    "from level_2.src.utils import utils\n",
    "from level_2.src.data.data_load import DataLoad\n",
    "from level_2.src.data.data_validation import DataValidation\n",
    "from level_2.src.data.data_transform import DataTransform\n",
    "from level_2.src.data.data_preprocess import DataPreprocess\n",
    "from level_2.src.train.model_training import ModelTraining\n",
    "from level_2.src.evaluation.classifier_eval import ClassifierEvaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mReading data from CSV file...\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mData read successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_data_file = os.path.join(ROOT_DIR, 'level_2', 'data', 'raw', 'train.csv')\n",
    "\n",
    "data_load = DataLoad()\n",
    "df = data_load.run(train_data_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation started\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation passed\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mValidation successeful\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_validation = DataValidation()\n",
    "\n",
    "is_valid = data_validation.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = DataTransform(df)\n",
    "\n",
    "x_train, x_test, y_train, y_test = data_transform.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1701960364665, experiment_id='1', last_update_time=1701960364665, lifecycle_stage='active', name='prob_loan', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"prob_loan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-07 14:26:59\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-07 14:27:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-07 14:27:01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-07 14:27:01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.7076126693231048\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='baseline'):\n",
    "    mlflow.set_tag('model_name', 'baseline')\n",
    "    \n",
    "    # 1. preprocessing\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('imputer', MeanMedianImputer(variables=utils.load_config().get('imputer_variables'))),\n",
    "            ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocessor = DataPreprocess(pipe)    \n",
    "    preprocessor.train(x_train)\n",
    "    \n",
    "    x_train_processed = preprocessor.transform(x_train)    \n",
    "    x_test_processed = preprocessor.transform(x_test)\n",
    "    \n",
    "    joblib.dump(preprocessor, os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "    \n",
    "    # 1.1. artifact logging - preprocessor\n",
    "    mlflow.log_artifact(os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "    \n",
    "    # 1.2. artifact params - config\n",
    "    log_params = {\n",
    "        'imputer': pipe['imputer'],\n",
    "        'scaler': pipe['scaler']\n",
    "    }\n",
    "    mlflow.log_params(params=log_params)\n",
    "    \n",
    "    # 2. begin with cross validation\n",
    "    model = LogisticRegression(random_state=utils.load_config().get('random_state'))\n",
    "    model_eval = ClassifierEvaluation(model, x_train_processed, y_train, k_fold=5)\n",
    "    roc_auc_scores = model_eval.cross_val_eval()\n",
    "    \n",
    "    \n",
    "    # 2.1 log metrics\n",
    "    mlflow.log_metric('roc_auc_scores', roc_auc_scores.mean())\n",
    "    \n",
    "    # 3. train model\n",
    "    model.fit(x_train_processed, y_train)\n",
    "    \n",
    "    # 4. evaluate model under test data\n",
    "    y_pred = model_eval.model.predict_proba(x_test_processed)[:, 1]\n",
    "    val_roc_auc_score = model_eval.evaluate_predictions(y_test, y_pred)\n",
    "    \n",
    "    # 4.1 log metrics\n",
    "    mlflow.log_metric('val_roc_auc_score', val_roc_auc_score)\n",
    "    \n",
    "    # 5. log model\n",
    "    mlflow.sklearn.log_model(model, 'lr_model', pyfunc_predict_fn='predict_proba')\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Discretiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2023-12-07 14:30:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing started\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mTransforming data\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mPreprocessing finished\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:00\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression started.\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCross validation evaluation for model LogisticRegression finished.\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mEvaluation of predictions started.\u001b[0m\n",
      "\u001b[2m2023-12-07 14:30:01\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mROC AUC score: 0.7985133358298327\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 472.67it/s] \n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 153.10it/s]\n",
      "2023/12/07 14:30:06 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "2023/12/07 14:30:06 INFO mlflow.models.evaluation.default_evaluator: Evaluating candidate model:\n",
      "2023/12/07 14:30:06 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2023/12/07 14:30:06 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2023/12/07 14:30:06 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2023/12/07 14:30:09 INFO mlflow.models.evaluation.default_evaluator: Shap explainer LinearExplainer is used.\n",
      "2023/12/07 14:30:09 WARNING mlflow.models.evaluation.default_evaluator: Logging explainer failed. Reason: AttributeError(\"'LogisticRegression' object has no attribute 'save'\"). Set logging level to DEBUG to see the full traceback.\n",
      "2023/12/07 14:30:12 INFO mlflow.models.evaluation.default_evaluator: Evaluating baseline model:\n",
      "2023/12/07 14:30:12 INFO mlflow.models.evaluation.default_evaluator: Computing model predictions.\n",
      "2023/12/07 14:30:12 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is 1, negative label is 0.\n",
      "2023/12/07 14:30:12 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2023/12/07 14:30:12 INFO mlflow.models.evaluation.base: Validating generated model metrics\n",
      "2023/12/07 14:30:12 INFO mlflow.models.evaluation.base: Model validation passed!\n",
      "  0%|          | 147/49500 [01:13<6:49:07,  2.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39m# 7. log model with threshold\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m mlflow\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     candidate_model_uri,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     eval_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     baseline_model\u001b[39m=\u001b[39mbaseline_model_uri\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m mlflow\u001b[39m.\u001b[39;49mshap\u001b[39m.\u001b[39;49mlog_explanation(model\u001b[39m.\u001b[39;49mpredict, x_test_processed\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bem/repos/ml_flow/level_2/notebooks/c04_baseline_mlflow.ipynb#X25sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m mlflow\u001b[39m.\u001b[39mend_run()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/ml_flow/lib/python3.10/site-packages/mlflow/shap/__init__.py:275\u001b[0m, in \u001b[0;36mlog_explanation\u001b[0;34m(predict_function, features, artifact_path)\u001b[0m\n\u001b[1;32m    273\u001b[0m background_data \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mkmeans(features, \u001b[39mmin\u001b[39m(_MAXIMUM_BACKGROUND_DATA_SIZE, \u001b[39mlen\u001b[39m(features)))\n\u001b[1;32m    274\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mKernelExplainer(predict_function, background_data)\n\u001b[0;32m--> 275\u001b[0m shap_values \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mshap_values(features)\n\u001b[1;32m    277\u001b[0m _log_numpy(explainer\u001b[39m.\u001b[39mexpected_value, _BASE_VALUES_FILE_NAME, artifact_path)\n\u001b[1;32m    278\u001b[0m _log_numpy(shap_values, _SHAP_VALUES_FILE_NAME, artifact_path)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/ml_flow/lib/python3.10/site-packages/shap/explainers/_kernel.py:244\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_index:\n\u001b[1;32m    243\u001b[0m     data \u001b[39m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m], index_name)\n\u001b[0;32m--> 244\u001b[0m explanations\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplain(data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mgc_collect\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    246\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/ml_flow/lib/python3.10/site-packages/shap/explainers/_kernel.py:442\u001b[0m, in \u001b[0;36mKernelExplainer.explain\u001b[0;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernelWeights[nfixed_samples:] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m weight_left \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernelWeights[nfixed_samples:]\u001b[39m.\u001b[39msum()\n\u001b[1;32m    441\u001b[0m \u001b[39m# execute the model on the synthetic samples we have created\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m    444\u001b[0m \u001b[39m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[39;00m\n\u001b[1;32m    445\u001b[0m phi \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mgroups_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.13/envs/ml_flow/lib/python3.10/site-packages/shap/explainers/_kernel.py:590\u001b[0m, in \u001b[0;36mKernelExplainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m eyVal \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mD)\n\u001b[1;32m    589\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN):\n\u001b[0;32m--> 590\u001b[0m     eyVal \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my[i \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN \u001b[39m+\u001b[39m j, :] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mweights[j]\n\u001b[1;32m    592\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mey[i, :] \u001b[39m=\u001b[39m eyVal\n\u001b[1;32m    593\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsamplesRun \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='with_discretiser'):\n",
    "    mlflow.set_tag('model_name', 'lr_discretiser')\n",
    "    \n",
    "    # 1. preprocessing\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('imputer', MeanMedianImputer(variables=utils.load_config().get('imputer_variables'))),\n",
    "            ('discretiser', EqualFrequencyDiscretiser(variables=utils.load_config().get('discretiser_variables'))),\n",
    "            ('scaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocessor = DataPreprocess(pipe)    \n",
    "    preprocessor.train(x_train)\n",
    "    \n",
    "    x_train_processed = preprocessor.transform(x_train)    \n",
    "    x_test_processed = preprocessor.transform(x_test)\n",
    "    \n",
    "    joblib.dump(preprocessor, os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "    \n",
    "    # 1.1. artifact logging - preprocessor\n",
    "    mlflow.log_artifact(os.path.join(ROOT_DIR, 'level_2', 'models', 'preprocessor.joblib'))\n",
    "    \n",
    "    # 1.2. artifact params - config\n",
    "    log_params = {\n",
    "        'imputer': pipe['imputer'],\n",
    "        'discretiser': pipe['discretiser'],\n",
    "        'scaler': pipe['scaler']\n",
    "    }\n",
    "    mlflow.log_params(params=log_params)\n",
    "    \n",
    "    # 2. begin with cross validation\n",
    "    model = LogisticRegression(random_state=utils.load_config().get('random_state'))\n",
    "    model_eval = ClassifierEvaluation(model, x_train_processed, y_train, k_fold=5)\n",
    "    roc_auc_scores = model_eval.cross_val_eval()\n",
    "    \n",
    "    \n",
    "    # 2.1 log metrics\n",
    "    mlflow.log_metric('roc_auc_scores', roc_auc_scores.mean())\n",
    "    \n",
    "    # 3. train model\n",
    "    model.fit(x_train_processed, y_train)\n",
    "    \n",
    "    # 4. evaluate model under test data\n",
    "    y_pred = model_eval.model.predict_proba(x_test_processed)[:, 1]\n",
    "    val_roc_auc_score = model_eval.evaluate_predictions(y_test, y_pred)\n",
    "    \n",
    "    # 4.1 log metrics\n",
    "    mlflow.log_metric('val_roc_auc_score', val_roc_auc_score)\n",
    "    \n",
    "    # 5. log model\n",
    "    candidate_model_uri = mlflow.sklearn.log_model(model, 'lr_discretiser').model_uri\n",
    "    \n",
    "    # 6. infer signature\n",
    "    signature = infer_signature(x_test_processed, y_test)\n",
    "    eval_data = x_test_processed\n",
    "    eval_data['label'] = y_test\n",
    "    \n",
    "    threshold = {\n",
    "        'accuracy_score': MetricThreshold(\n",
    "            threshold=0.7,\n",
    "            min_absolute_change=0.05,\n",
    "            min_relative_change=0.05,\n",
    "            greater_is_better=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    baseline_model = DummyClassifier(\n",
    "                        strategy='uniform',\n",
    "                        random_state=utils.load_config().get('random_state')\n",
    "                    ).fit(x_train_processed, y_train)\n",
    "    baseline_model_uri = mlflow.sklearn.log_model(baseline_model, 'baseline_model', signature=signature).model_uri\n",
    "    \n",
    "    # 7. log model with threshold\n",
    "    mlflow.evaluate(\n",
    "        candidate_model_uri,\n",
    "        eval_data,\n",
    "        targets='label',\n",
    "        model_type='classifier',\n",
    "        validation_thresholds=threshold,\n",
    "        baseline_model=baseline_model_uri\n",
    "    )\n",
    "    \n",
    "    mlflow.shap.log_explanation(model.predict, x_test_processed.drop('label', axis=1))\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
